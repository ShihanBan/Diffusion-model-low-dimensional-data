{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data generation\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optax==0.1.7\n",
      "  Downloading optax-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.1.7)\n",
      "Requirement already satisfied: jax>=0.1.55 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.4.13)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.4.13)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (1.24.3)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (0.1.8)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (4.11.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.1.55->optax==0.1.7) (3.11.0)\n",
      "Downloading optax-0.1.7-py3-none-any.whl (154 kB)\n",
      "Installing collected packages: optax\n",
      "  Attempting uninstall: optax\n",
      "    Found existing installation: optax 0.1.8\n",
      "    Uninstalling optax-0.1.8:\n",
      "      Successfully uninstalled optax-0.1.8\n",
      "Successfully installed optax-0.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optax==0.1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate      # (Windows PowerShell: .\\.venv\\Scripts\\Activate.ps1)\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.4.13-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax)\n",
      "  Downloading ml_dtypes-0.2.0-cp38-cp38-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax) (3.11.0)\n",
      "Downloading jaxlib-0.4.13-cp38-cp38-macosx_11_0_arm64.whl (60.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp38-cp38-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518704 sha256=dbbf3d3b2dbd69848959967f299880ebf4e58e8b674b4b5c360ba5b778de3c51\n",
      "  Stored in directory: /Users/banshihan/Library/Caches/pip/wheels/46/d9/15/d2800d4089dc4c77299ac7513c6aa1036f5491edbd2bf6ba16\n",
      "Successfully built jax\n",
      "Installing collected packages: ml-dtypes, jaxlib, jax\n",
      "Successfully installed jax-0.4.13 jaxlib-0.4.13 ml-dtypes-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U jax jaxlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flax\n",
      "  Downloading flax-0.7.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (1.24.3)\n",
      "Requirement already satisfied: jax>=0.4.2 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (0.4.13)\n",
      "Collecting msgpack (from flax)\n",
      "  Downloading msgpack-1.1.0.tar.gz (167 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting optax (from flax)\n",
      "  Downloading optax-0.1.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting orbax-checkpoint (from flax)\n",
      "  Downloading orbax_checkpoint-0.2.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorstore (from flax)\n",
      "  Downloading tensorstore-0.1.45-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting rich>=11.1 (from flax)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (6.8.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from rich>=11.1->flax) (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax->flax) (2.1.0)\n",
      "Collecting chex>=0.1.7 (from optax->flax)\n",
      "  Downloading chex-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax->flax) (0.4.13)\n",
      "Collecting cached_property (from orbax-checkpoint->flax)\n",
      "  Downloading cached_property-2.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_resources in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from orbax-checkpoint->flax) (5.2.0)\n",
      "Collecting etils (from orbax-checkpoint->flax)\n",
      "  Downloading etils-1.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest_asyncio in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.6)\n",
      "Collecting dm-tree>=0.1.5 (from chex>=0.1.7->optax->flax)\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.7->optax->flax)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.4.2->flax) (3.11.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading flax-0.7.2-py3-none-any.whl (226 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading optax-0.1.8-py3-none-any.whl (199 kB)\n",
      "Downloading orbax_checkpoint-0.2.3-py3-none-any.whl (81 kB)\n",
      "Downloading tensorstore-0.1.45-cp38-cp38-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading cached_property-2.0.1-py3-none-any.whl (7.4 kB)\n",
      "Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "Downloading dm_tree-0.1.8-cp38-cp38-macosx_11_0_arm64.whl (110 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: msgpack\n",
      "  Building wheel for msgpack (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack: filename=msgpack-1.1.0-cp38-cp38-macosx_11_0_arm64.whl size=83182 sha256=9112e7a38080ae0a7a091a1b5f45fd30e3db31545714ee284be90eb489cdab0a\n",
      "  Stored in directory: /Users/banshihan/Library/Caches/pip/wheels/55/aa/93/797450f0b3d3ac6906a2a32306efbb304940a5a8eb5bdff767\n",
      "Successfully built msgpack\n",
      "Installing collected packages: dm-tree, toolz, tensorstore, msgpack, mdurl, etils, cached_property, markdown-it-py, rich, orbax-checkpoint, chex, optax, flax\n",
      "Successfully installed cached_property-2.0.1 chex-0.1.7 dm-tree-0.1.8 etils-1.3.0 flax-0.7.2 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 optax-0.1.8 orbax-checkpoint-0.2.3 rich-14.0.0 tensorstore-0.1.45 toolz-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import LinearGaussianDataset, SigmoidDataset, SphereDataset\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = LinearGaussianDataset(seed=seed, dimension=2, padding_dimension=1)\n",
    "\n",
    "# 生成数据批次\n",
    "batch_size = 1000\n",
    "data = dataset.get_batch(batch_size)  ##:contentReference[oaicite:22]{index=22}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear case data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/banshihan/Documents/GitHub/homework-3-ShihanBan/Diffusion-model-low-dimensional-data\n",
      "__init__.py              diffusion_utils.py       \u001b[31mseed_linpadding_expts.sh\u001b[m\u001b[m\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m              \u001b[34mgenerated_data\u001b[m\u001b[m           training.py\n",
      "data_generation.ipynb    model.py                 utils.py\n",
      "datasets.py              networks.py\n",
      "diffusion.py             run.py\n"
     ]
    }
   ],
   "source": [
    "!pwd  # 看你当前在哪\n",
    "!ls   # 确保能看到 seed_linpadding_expts.sh 和 run.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell 1: 导入\n",
    "import numpy as np\n",
    "from datasets import LinearGaussianDataset    # 原仓库中的类定义 :contentReference[oaicite:0]{index=0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3_pad9_seed2 → shape = (12800000, 12)\n",
      "d3_pad9_seed3 → shape = (12800000, 12)\n",
      "d3_pad9_seed4 → shape = (12800000, 12)\n",
      "d3_pad17_seed2 → shape = (12800000, 20)\n",
      "d3_pad17_seed3 → shape = (12800000, 20)\n",
      "d3_pad17_seed4 → shape = (12800000, 20)\n",
      "d6_pad6_seed2 → shape = (12800000, 12)\n",
      "d6_pad6_seed3 → shape = (12800000, 12)\n",
      "d6_pad6_seed4 → shape = (12800000, 12)\n",
      "d6_pad14_seed2 → shape = (12800000, 20)\n",
      "d6_pad14_seed3 → shape = (12800000, 20)\n",
      "d6_pad14_seed4 → shape = (12800000, 20)\n",
      "d9_pad3_seed2 → shape = (12800000, 12)\n",
      "d9_pad3_seed3 → shape = (12800000, 12)\n",
      "d9_pad3_seed4 → shape = (12800000, 12)\n",
      "d9_pad11_seed2 → shape = (12800000, 20)\n",
      "d9_pad11_seed3 → shape = (12800000, 20)\n",
      "d9_pad11_seed4 → shape = (12800000, 20)\n",
      "d12_pad8_seed2 → shape = (12800000, 20)\n",
      "d12_pad8_seed3 → shape = (12800000, 20)\n",
      "d12_pad8_seed4 → shape = (12800000, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import LinearGaussianDataset\n",
    "\n",
    "# 固定 intrinsic dimension r* = 3\n",
    "r_star = 3  \n",
    "\n",
    "# 定义 ambient 维度到 padding_dim 的映射（对应脚本里的组合）\n",
    "dd_to_paddings = {\n",
    "    3: [9, 17],\n",
    "    6: [6, 14],\n",
    "    9: [3, 11],\n",
    "    12:[8],      # 脚本里只对 12 维做了一个 padding_dim 组合\n",
    "}\n",
    "\n",
    "# 三个随机种子 ds ∈ {2,3,4}\n",
    "seeds = [2, 3, 4]\n",
    "\n",
    "# 样本数 N = num_batches * batch_size = 100000 * 128\n",
    "N = 100_000 * 128  \n",
    "\n",
    "# 存放所有生成结果的字典\n",
    "data_store = {}\n",
    "\n",
    "for dd, paddings in dd_to_paddings.items():\n",
    "    for pad in paddings:\n",
    "        for seed in seeds:\n",
    "            key = f\"d{dd}_pad{pad}_seed{seed}\"\n",
    "            # 实例化 Dataset\n",
    "            ds = LinearGaussianDataset(\n",
    "                seed=seed,\n",
    "                dimension=dd,\n",
    "                intrinsic_dimension=r_star,\n",
    "                padding_dimension=pad,\n",
    "                var_added=0.0\n",
    "            )\n",
    "            # 一次性生成 N 个样本\n",
    "            X = ds.get_batch(N)  # jax.numpy array of shape (N, dd+pad)\n",
    "            # 转为 NumPy 并存储\n",
    "            data_store[key] = np.array(X)\n",
    "            print(f\"{key} → shape = {data_store[key].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 1. 时间嵌入模块\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "# 2. 扩散模型网络结构\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, time_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_dim),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + time_dim, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        x = torch.cat([x, t_emb], dim=1)\n",
    "        return self.input_mlp(x)\n",
    "\n",
    "# 3. 扩散过程管理类\n",
    "class DiffusionProcess:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, device='cuda'):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.device = device\n",
    "        \n",
    "        # 预计算扩散计划参数\n",
    "        self.beta = torch.linspace(beta_start, beta_end, noise_steps, device=device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "    \n",
    "    def sample_timesteps(self, batch_size):\n",
    "        return torch.randint(0, self.noise_steps, (batch_size,), device=self.device)\n",
    "    \n",
    "    def add_noise(self, x, t):\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None]\n",
    "        noise = torch.randn_like(x)\n",
    "        return sqrt_alpha_bar * x + sqrt_one_minus_alpha_bar * noise, noise\n",
    "    \n",
    "    def denoise_step(self, model, x, t):\n",
    "        with torch.no_grad():\n",
    "            pred_noise = model(x, t)\n",
    "            alpha = self.alpha[t][:, None]\n",
    "            alpha_bar = self.alpha_bar[t][:, None]\n",
    "            beta = self.beta[t][:, None]\n",
    "            \n",
    "            x = (x - (beta / torch.sqrt(1 - alpha_bar)) * pred_noise) / torch.sqrt(alpha)\n",
    "            if t[0] > 0:  # 添加过程噪声\n",
    "                x += torch.sqrt(beta) * torch.randn_like(x)\n",
    "        return x\n",
    "\n",
    "# 4. 训练函数\n",
    "def train_diffusion_model(data_dict, device='cuda', num_epochs=10, batch_size=128, lr=1e-3):\n",
    "    # 遍历每个数据集\n",
    "    for key in data_dict:\n",
    "        # 数据准备\n",
    "        data_np = data_dict[key]\n",
    "        input_dim = data_np.shape[1]\n",
    "        dataset = TensorDataset(torch.tensor(data_np).float())\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "        \n",
    "        # 初始化模型和优化器\n",
    "        model = DiffusionModel(input_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        diffusion = DiffusionProcess(device=device)\n",
    "        \n",
    "        print(f\"\\nTraining on dataset: {key} (dim={input_dim})\")\n",
    "        \n",
    "        # 训练循环\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "            for batch in dataloader:\n",
    "                x = batch[0].to(device)\n",
    "                \n",
    "                # 采样时间步和添加噪声\n",
    "                t = diffusion.sample_timesteps(x.size(0))\n",
    "                x_noisy, true_noise = diffusion.add_noise(x, t)\n",
    "                \n",
    "                # 前向传播和损失计算\n",
    "                pred_noise = model(x_noisy, t)\n",
    "                loss = nn.MSELoss()(pred_noise, true_noise)\n",
    "                \n",
    "                # 反向传播\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * x.size(0)\n",
    "            \n",
    "            # 打印训练进度\n",
    "            avg_loss = total_loss / len(dataloader.dataset)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "        # 保存训练好的模型\n",
    "        torch.save(model.state_dict(), f\"diffusion_model_{key}.pth\")\n",
    "        print(f\"Saved model for {key}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 执行训练\n",
    "if __name__ == \"__main__\":\n",
    "    # 检查CUDA可用性\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 这里需要先运行用户提供的生成数据的代码来填充data_store\n",
    "    # 假设data_store已经包含生成的数据\n",
    "    \n",
    "    # 开始训练\n",
    "    train_diffusion_model(\n",
    "        data_store,\n",
    "        device=device,\n",
    "        num_epochs=10,\n",
    "        batch_size=256,\n",
    "        lr=1e-3\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycourse)",
   "language": "python",
   "name": "pycourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
