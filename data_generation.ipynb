{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data generation\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optax==0.1.7\n",
      "  Downloading optax-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (2.1.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.1.7)\n",
      "Requirement already satisfied: jax>=0.1.55 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.4.13)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (0.4.13)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax==0.1.7) (1.24.3)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (0.1.8)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (4.11.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.1.55->optax==0.1.7) (3.11.0)\n",
      "Downloading optax-0.1.7-py3-none-any.whl (154 kB)\n",
      "Installing collected packages: optax\n",
      "  Attempting uninstall: optax\n",
      "    Found existing installation: optax 0.1.8\n",
      "    Uninstalling optax-0.1.8:\n",
      "      Successfully uninstalled optax-0.1.8\n",
      "Successfully installed optax-0.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optax==0.1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from opencv-python) (1.24.3)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate      # (Windows PowerShell: .\\.venv\\Scripts\\Activate.ps1)\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax\n",
      "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jaxlib\n",
      "  Downloading jaxlib-0.4.13-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax)\n",
      "  Downloading ml_dtypes-0.2.0-cp38-cp38-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax) (3.11.0)\n",
      "Downloading jaxlib-0.4.13-cp38-cp38-macosx_11_0_arm64.whl (60.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp38-cp38-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518704 sha256=dbbf3d3b2dbd69848959967f299880ebf4e58e8b674b4b5c360ba5b778de3c51\n",
      "  Stored in directory: /Users/banshihan/Library/Caches/pip/wheels/46/d9/15/d2800d4089dc4c77299ac7513c6aa1036f5491edbd2bf6ba16\n",
      "Successfully built jax\n",
      "Installing collected packages: ml-dtypes, jaxlib, jax\n",
      "Successfully installed jax-0.4.13 jaxlib-0.4.13 ml-dtypes-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U jax jaxlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flax\n",
      "  Downloading flax-0.7.2-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (1.24.3)\n",
      "Requirement already satisfied: jax>=0.4.2 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (0.4.13)\n",
      "Collecting msgpack (from flax)\n",
      "  Downloading msgpack-1.1.0.tar.gz (167 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting optax (from flax)\n",
      "  Downloading optax-0.1.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting orbax-checkpoint (from flax)\n",
      "  Downloading orbax_checkpoint-0.2.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorstore (from flax)\n",
      "  Downloading tensorstore-0.1.45-cp38-cp38-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting rich>=11.1 (from flax)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from flax) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from jax>=0.4.2->flax) (6.8.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from rich>=11.1->flax) (2.15.1)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax->flax) (2.1.0)\n",
      "Collecting chex>=0.1.7 (from optax->flax)\n",
      "  Downloading chex-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from optax->flax) (0.4.13)\n",
      "Collecting cached_property (from orbax-checkpoint->flax)\n",
      "  Downloading cached_property-2.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_resources in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from orbax-checkpoint->flax) (5.2.0)\n",
      "Collecting etils (from orbax-checkpoint->flax)\n",
      "  Downloading etils-1.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: nest_asyncio in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.6)\n",
      "Collecting dm-tree>=0.1.5 (from chex>=0.1.7->optax->flax)\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-macosx_11_0_arm64.whl.metadata (1.9 kB)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.7->optax->flax)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/banshihan/miniconda3/envs/pycourse/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.4.2->flax) (3.11.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading flax-0.7.2-py3-none-any.whl (226 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading optax-0.1.8-py3-none-any.whl (199 kB)\n",
      "Downloading orbax_checkpoint-0.2.3-py3-none-any.whl (81 kB)\n",
      "Downloading tensorstore-0.1.45-cp38-cp38-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading chex-0.1.7-py3-none-any.whl (89 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading cached_property-2.0.1-py3-none-any.whl (7.4 kB)\n",
      "Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "Downloading dm_tree-0.1.8-cp38-cp38-macosx_11_0_arm64.whl (110 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: msgpack\n",
      "  Building wheel for msgpack (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for msgpack: filename=msgpack-1.1.0-cp38-cp38-macosx_11_0_arm64.whl size=83182 sha256=9112e7a38080ae0a7a091a1b5f45fd30e3db31545714ee284be90eb489cdab0a\n",
      "  Stored in directory: /Users/banshihan/Library/Caches/pip/wheels/55/aa/93/797450f0b3d3ac6906a2a32306efbb304940a5a8eb5bdff767\n",
      "Successfully built msgpack\n",
      "Installing collected packages: dm-tree, toolz, tensorstore, msgpack, mdurl, etils, cached_property, markdown-it-py, rich, orbax-checkpoint, chex, optax, flax\n",
      "Successfully installed cached_property-2.0.1 chex-0.1.7 dm-tree-0.1.8 etils-1.3.0 flax-0.7.2 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.1.0 optax-0.1.8 orbax-checkpoint-0.2.3 rich-14.0.0 tensorstore-0.1.45 toolz-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear case data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/banshihan/Documents/GitHub/homework-3-ShihanBan/Diffusion-model-low-dimensional-data\n",
      "__init__.py              diffusion.py             networks.py\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m              diffusion_model.py       run.py\n",
      "\u001b[34mdata\u001b[m\u001b[m                     diffusion_utils.py       \u001b[31mseed_linpadding_expts.sh\u001b[m\u001b[m\n",
      "data_generation.ipynb    \u001b[34mgenerated_data\u001b[m\u001b[m           training.py\n",
      "datasets.py              model.py                 utils.py\n"
     ]
    }
   ],
   "source": [
    "!pwd  # 看你当前在哪\n",
    "!ls   # 确保能看到 seed_linpadding_expts.sh 和 run.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Cell 1: 导入\n",
    "import numpy as np\n",
    "from datasets import LinearGaussianDataset    # 原仓库中的类定义 :contentReference[oaicite:0]{index=0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3_pad9_seed2 → shape = (12800000, 12)\n",
      "d3_pad9_seed3 → shape = (12800000, 12)\n",
      "d3_pad9_seed4 → shape = (12800000, 12)\n",
      "d3_pad17_seed2 → shape = (12800000, 20)\n",
      "d3_pad17_seed3 → shape = (12800000, 20)\n",
      "d3_pad17_seed4 → shape = (12800000, 20)\n",
      "d6_pad6_seed2 → shape = (12800000, 12)\n",
      "d6_pad6_seed3 → shape = (12800000, 12)\n",
      "d6_pad6_seed4 → shape = (12800000, 12)\n",
      "d6_pad14_seed2 → shape = (12800000, 20)\n",
      "d6_pad14_seed3 → shape = (12800000, 20)\n",
      "d6_pad14_seed4 → shape = (12800000, 20)\n",
      "d9_pad3_seed2 → shape = (12800000, 12)\n",
      "d9_pad3_seed3 → shape = (12800000, 12)\n",
      "d9_pad3_seed4 → shape = (12800000, 12)\n",
      "d9_pad11_seed2 → shape = (12800000, 20)\n",
      "d9_pad11_seed3 → shape = (12800000, 20)\n",
      "d9_pad11_seed4 → shape = (12800000, 20)\n",
      "d12_pad8_seed2 → shape = (12800000, 20)\n",
      "d12_pad8_seed3 → shape = (12800000, 20)\n",
      "d12_pad8_seed4 → shape = (12800000, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import LinearGaussianDataset\n",
    "\n",
    "# 固定 intrinsic dimension r* = 3\n",
    "r_star = 3  \n",
    "\n",
    "# 定义 ambient 维度到 padding_dim 的映射（对应脚本里的组合）\n",
    "dd_to_paddings = {\n",
    "    3: [9, 17],\n",
    "    6: [6, 14],\n",
    "    9: [3, 11],\n",
    "    12:[8],      # 脚本里只对 12 维做了一个 padding_dim 组合\n",
    "}\n",
    "\n",
    "# 三个随机种子 ds ∈ {2,3,4}\n",
    "seeds = [2, 3, 4]\n",
    "\n",
    "# 样本数 N = num_batches * batch_size = 100000 * 128\n",
    "N = 100_000 * 128  \n",
    "\n",
    "# 存放所有生成结果的字典\n",
    "data_store = {}\n",
    "\n",
    "for dd, paddings in dd_to_paddings.items():\n",
    "    for pad in paddings:\n",
    "        for seed in seeds:\n",
    "            key = f\"d{dd}_pad{pad}_seed{seed}\"\n",
    "            # 实例化 Dataset\n",
    "            ds = LinearGaussianDataset(\n",
    "                seed=seed,\n",
    "                dimension=dd,\n",
    "                intrinsic_dimension=r_star,\n",
    "                padding_dimension=pad,\n",
    "                var_added=0.0\n",
    "            )\n",
    "            # 一次性生成 N 个样本\n",
    "            X = ds.get_batch(N)  # jax.numpy array of shape (N, dd+pad)\n",
    "            # 转为 NumPy 并存储\n",
    "            data_store[key] = np.array(X)\n",
    "            print(f\"{key} → shape = {data_store[key].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 1. 时间嵌入模块\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, t):\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "# 2. 扩散模型网络结构\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, input_dim, time_dim=32):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_dim),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "        )\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim + time_dim, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(256, input_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        x = torch.cat([x, t_emb], dim=1)\n",
    "        return self.input_mlp(x)\n",
    "\n",
    "# 3. 扩散过程管理类\n",
    "class DiffusionProcess:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, device='cuda'):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.device = device\n",
    "        \n",
    "        # 预计算扩散计划参数\n",
    "        self.beta = torch.linspace(beta_start, beta_end, noise_steps, device=device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "    \n",
    "    def sample_timesteps(self, batch_size):\n",
    "        return torch.randint(0, self.noise_steps, (batch_size,), device=self.device)\n",
    "    \n",
    "    def add_noise(self, x, t):\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None]\n",
    "        noise = torch.randn_like(x)\n",
    "        return sqrt_alpha_bar * x + sqrt_one_minus_alpha_bar * noise, noise\n",
    "    \n",
    "    def denoise_step(self, model, x, t):\n",
    "        with torch.no_grad():\n",
    "            pred_noise = model(x, t)\n",
    "            alpha = self.alpha[t][:, None]\n",
    "            alpha_bar = self.alpha_bar[t][:, None]\n",
    "            beta = self.beta[t][:, None]\n",
    "            \n",
    "            x = (x - (beta / torch.sqrt(1 - alpha_bar)) * pred_noise) / torch.sqrt(alpha)\n",
    "            if t[0] > 0:  # 添加过程噪声\n",
    "                x += torch.sqrt(beta) * torch.randn_like(x)\n",
    "        return x\n",
    "    def sample(self, model, num_samples, input_dim, device='cuda'):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # 初始噪声\n",
    "            x = torch.randn((num_samples, input_dim)).to(device)\n",
    "            \n",
    "            # 反向扩散过程\n",
    "            for t in reversed(range(self.noise_steps)):\n",
    "                t_batch = torch.full((num_samples,), t, device=device)\n",
    "                x = self.denoise_step(model, x, t_batch)\n",
    "        return x.cpu().numpy()\n",
    "\n",
    "def compute_metrics(model, original_data, generated_data, device='cuda'):\n",
    "    metrics = {}\n",
    "    \n",
    "    # 指标1: 本征维度计算（使用模型参数）\n",
    "    weights = []\n",
    "    for param in model.parameters():\n",
    "        if len(param.shape) == 2:  # 只处理权重矩阵\n",
    "            weights.append(param.detach().cpu().numpy())\n",
    "    W = np.concatenate([w.flatten() for w in weights])\n",
    "    U, s, Vt = svd(W.reshape(-1, W.shape[0]), full_matrices=False)\n",
    "    explained_variance = np.cumsum(s**2) / np.sum(s**2)\n",
    "    intrinsic_dim = np.argmax(explained_variance >= 0.95) + 1\n",
    "    metrics['intrinsic_dim'] = intrinsic_dim\n",
    "    \n",
    "    # 指标2: 解码器非零行平均数\n",
    "    decoder_weights = model.input_mlp[0].weight.detach().cpu().numpy()\n",
    "    threshold = 1e-5  # 非零阈值\n",
    "    nonzero_rows = np.mean([np.any(np.abs(row) > threshold) for row in decoder_weights])\n",
    "    metrics['decoder_nonzero_rows'] = nonzero_rows\n",
    "\n",
    "    # 指标3: 归一化特征值误差\n",
    "    # 原始数据协方差\n",
    "    orig_cov = np.cov(original_data.T)\n",
    "    orig_eigvals = np.linalg.eigvalsh(orig_cov)\n",
    "    \n",
    "    # 生成数据协方差\n",
    "    gen_cov = np.cov(generated_data.T)\n",
    "    gen_eigvals = np.linalg.eigvalsh(gen_cov)\n",
    "    \n",
    "    # 计算归一化误差\n",
    "    error = np.linalg.norm(orig_eigvals - gen_eigvals) / np.linalg.norm(orig_eigvals)\n",
    "    metrics['normalized_eigen_error'] = error\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# 5. 训练函数\n",
    "def train_diffusion_model(data_dict, device='cuda', num_epochs=10, batch_size=128, lr=1e-3):\n",
    "    all_metrics = {}\n",
    "    \n",
    "    for key in tqdm(data_dict, desc=\"Datasets\"):\n",
    "        # 数据准备\n",
    "        data_np = data_dict[key]\n",
    "        input_dim = data_np.shape[1]\n",
    "        dataset = TensorDataset(torch.tensor(data_np).float())\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "        \n",
    "        # 模型初始化\n",
    "        model = DiffusionModel(input_dim).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        diffusion = DiffusionProcess(device=device)\n",
    "        \n",
    "        # 训练循环\n",
    "        tqdm.write(f\"\\n=== Training {key} (dim={input_dim}) ===\")\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "                x = batch[0].to(device)\n",
    "                \n",
    "                # 扩散过程\n",
    "                t = diffusion.sample_timesteps(x.size(0))\n",
    "                x_noisy, true_noise = diffusion.add_noise(x, t)\n",
    "                \n",
    "                # 优化步骤\n",
    "                optimizer.zero_grad()\n",
    "                pred_noise = model(x_noisy, t)\n",
    "                loss = nn.MSELoss()(pred_noise, true_noise)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item() * x.size(0)\n",
    "            \n",
    "            # 打印训练信息\n",
    "            avg_loss = total_loss / len(dataloader.dataset)\n",
    "            tqdm.write(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        # 保存模型\n",
    "        torch.save(model.state_dict(), f\"diffusion_{key}.pth\")\n",
    "        \n",
    "        # 生成样本并评估\n",
    "        generated_data = diffusion.sample(model, 5000, input_dim, device)\n",
    "        metrics = compute_metrics(model, data_np, generated_data)\n",
    "        all_metrics[key] = metrics\n",
    "        \n",
    "        # 保存评估结果\n",
    "        with open(f\"metrics_{key}.txt\", \"w\") as f:\n",
    "            f.write(f\"Intrinsic Dimension: {metrics['intrinsic_dim']}\\n\")\n",
    "            f.write(f\"Decoder Nonzero Rows: {metrics['decoder_nonzero_rows']:.4f}\\n\")\n",
    "            f.write(f\"Normalized Eigen Error: {metrics['normalized_eigen_error']:.4f}\\n\")\n",
    "        \n",
    "        tqdm.write(f\"\\nEvaluation for {key}:\")\n",
    "        tqdm.write(f\"Intrinsic Dim: {metrics['intrinsic_dim']}\")\n",
    "        tqdm.write(f\"Nonzero Rows: {metrics['decoder_nonzero_rows']:.4f}\")\n",
    "        tqdm.write(f\"Eigen Error: {metrics['normalized_eigen_error']:.4f}\\n\")\n",
    "    \n",
    "    return all_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training d3_pad9_seed2 (dim=12) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets:   0%|          | 0/21 [04:27<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.087585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datasets:   0%|          | 0/21 [06:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 5. 执行训练\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# ... 保持原有代码不变 ...\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 开始训练并获取指标\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_diffusion_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# 打印汇总表格\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Metrics Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 147\u001b[0m, in \u001b[0;36mtrain_diffusion_model\u001b[0;34m(data_dict, device, num_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    145\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    146\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    148\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# 扩散过程\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pycourse/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pycourse/lib/python3.8/site-packages/torch/utils/data/dataloader.py:627\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pycourse/lib/python3.8/site-packages/torch/autograd/profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pycourse/lib/python3.8/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5. 执行训练\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ... 保持原有代码不变 ...\n",
    "    \n",
    "    # 开始训练并获取指标\n",
    "    metrics = train_diffusion_model(\n",
    "        data_store,\n",
    "        device=device,\n",
    "        num_epochs=10,\n",
    "        batch_size=256,\n",
    "        lr=1e-3\n",
    "    )\n",
    "    \n",
    "    # 打印汇总表格\n",
    "    print(\"\\nFinal Metrics Summary:\")\n",
    "    print(f\"{'Dataset':<20} | {'Intrinsic Dim':<15} | {'Nonzero Rows':<15} | {'Eigen Error':<15}\")\n",
    "    for key in metrics:\n",
    "        m = metrics[key]\n",
    "        print(f\"{key:<20} | {m['intrinsic_dim']:<15} | {m['decoder_nonzero_rows']:<15.4f} | {m['normalized_eigen_error']:<15.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycourse)",
   "language": "python",
   "name": "pycourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
